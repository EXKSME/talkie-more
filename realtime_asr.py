import sounddevice as sd
import numpy as np
from funasr import AutoModel

# =========================
# 1. åˆå§‹åŒ–æ¨¡å‹
# =========================
model = AutoModel(
    model="paraformer-zh-streaming",
    device="mps"  # Intel Mac æ”¹æˆ "cpu"
)

# =========================
# 2. æµå¼å‚æ•°ï¼ˆå®˜æ–¹æ¨èï¼‰
# =========================
sample_rate = 16000
chunk_size = [0, 10, 5]  # 600ms
encoder_chunk_look_back = 4
decoder_chunk_look_back = 1

chunk_stride = chunk_size[1] * 960  # 10 * 60ms * 16000 = 9600 samples

# å…¨å±€ cacheï¼ˆé‡ç‚¹ï¼‰
cache = {}

# ç´¯è®¡éŸ³é¢‘ buffer
audio_buffer = np.zeros((0,), dtype=np.float32)

# ä¸Šä¸€æ¬¡æ‰“å°çš„æ–‡æœ¬ï¼ˆé˜²æ­¢é‡å¤åˆ·å±ï¼‰
last_text = ""


# =========================
# 3. å›è°ƒå‡½æ•°
# =========================
def record_callback(indata, frames, time, status):
    global audio_buffer, last_text

    if status:
        print(status)

    # sounddevice: (frames, channels) â†’ 1D float32
    audio = indata[:, 0].astype(np.float32)
    audio_buffer = np.concatenate([audio_buffer, audio])

    # æ¯æ»¡ä¸€ä¸ª chunk æ‰é€æ¨¡å‹
    while len(audio_buffer) >= chunk_stride:
        chunk = audio_buffer[:chunk_stride]
        audio_buffer = audio_buffer[chunk_stride:]

        res = model.generate(
            input=chunk,
            cache=cache,
            is_final=False,
            chunk_size=chunk_size,
            encoder_chunk_look_back=encoder_chunk_look_back,
            decoder_chunk_look_back=decoder_chunk_look_back,
        )

        if res and res[0].get("text"):
            text = res[0]["text"]
            if text != last_text:
                print(text, end="", flush=True)
                last_text = text


# =========================
# 4. å¯åŠ¨éº¦å…‹é£
# =========================
print("ğŸ™ æ­£åœ¨ç›‘å¬éº¦å…‹é£ï¼Œè¯´è¯å³å¯ï¼ˆCtrl+C ç»“æŸï¼‰")
with sd.InputStream(
    samplerate=sample_rate,
    channels=1,
    dtype="float32",
    callback=record_callback,
):
    try:
        while True:
            sd.sleep(1000)
    except KeyboardInterrupt:
        print("\nğŸ›‘ åœæ­¢å½•éŸ³")

        # é€šçŸ¥æ¨¡å‹æœ€åä¸€æ®µ
        model.generate(
            input=np.zeros((0,), dtype=np.float32),
            cache=cache,
            is_final=True,
            chunk_size=chunk_size,
            encoder_chunk_look_back=encoder_chunk_look_back,
            decoder_chunk_look_back=decoder_chunk_look_back,
        )
