import sounddevice as sd
import numpy as np
import time
import requests
from funasr import AutoModel

# =========================
# åŸºæœ¬é…ç½®
# =========================
SAMPLE_RATE = 16000
CHUNK_SIZE = [0, 10, 5]          # FunASR å®˜æ–¹æ¨è
ENCODER_LOOK_BACK = 4
DECODER_LOOK_BACK = 1
CHUNK_STRIDE = CHUNK_SIZE[1] * 960  # 600ms
SILENCE_TIMEOUT = 0.5             # å¥å­ç»“æŸé˜ˆå€¼ï¼ˆç§’ï¼‰

OLLAMA_MODEL = "qwen2.5:1.5b"
OLLAMA_URL = "http://localhost:11434/api/generate"

# =========================
# åˆå§‹åŒ– ASR æ¨¡å‹
# =========================
model = AutoModel(
    model="paraformer-zh-streaming",
    device="mps"  # Intel Mac æ”¹æˆ "cpu"
)

cache = {}
audio_buffer = np.zeros((0,), dtype=np.float32)

last_partial_text = ""
last_text_change_time = time.time()

# =========================
# Ollama è°ƒç”¨
# =========================
def call_ollama(prompt: str) -> str:
    resp = requests.post(
        OLLAMA_URL,
        json={
            "model": "qwen3:0.6b",
            "prompt": prompt,
            "stream": False
        },
        timeout=60
    )

    data = resp.json()

    # æƒ…å†µ 1ï¼šç»å…¸ generate API
    if "response" in data:
        return data["response"]

    # æƒ…å†µ 2ï¼šchat é£æ ¼
    if "message" in data and "content" in data["message"]:
        return data["message"]["content"]

    # æƒ…å†µ 3ï¼šé”™è¯¯
    if "error" in data:
        raise RuntimeError(f"Ollama error: {data['error']}")

    # å…œåº•
    raise RuntimeError(f"Unknown Ollama response: {data}")

# =========================
# Routerï¼ˆè§„åˆ™ä¼˜å…ˆï¼ŒDemo ç¨³å®šï¼‰
# =========================
def route(text: str) -> str:
    if any(k in text for k in ["å…¬å¼", "å¹³æ–¹", "åˆ†ä¹‹", "æ ¹å·", "æ±‚å’Œ", "ç§¯åˆ†", "ä¸Šæ ‡", "ä¸‹æ ‡", "latex"]):
        return "latex"
    if any(k in text for k in ["æµç¨‹å›¾", "ç”»ä¸ªæµç¨‹", "æµç¨‹æ˜¯", "å¦‚æœ", "å¦åˆ™", "mermaid"]):
        return "mermaid"
    if any(k in text for k in ["æ€»ç»“", "åˆ—ä¸€ä¸‹", "è¦ç‚¹", "å‡ ç‚¹", "æ­¥éª¤", "æ¸…å•"]):
        return "markdown"
    return "plain"

# =========================
# Prompt æ¨¡æ¿
# =========================
def build_prompt(text: str, mode: str) -> str:
    if mode == "markdown":
        return f"""
ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬ç¼–è¾‘å™¨ï¼Œè€Œä¸æ˜¯èŠå¤©åŠ©æ‰‹ã€‚

è¯·å°†ä¸‹é¢çš„å£è¿°å†…å®¹ï¼š
- åˆ é™¤å£è¯­åºŸè¯ï¼ˆå¦‚â€œæˆ‘è§‰å¾—â€â€œç„¶åâ€â€œå…¶å®â€ï¼‰
- ä¿®æ­£è¯­æ³•
- å¦‚æœæ˜¯æ¸…å•ã€æ­¥éª¤æˆ–è¦ç‚¹ï¼Œè¯·ç»“æ„åŒ–æˆ Markdown

ã€åªè¾“å‡º JSONï¼Œä¸è¦è§£é‡Šã€‘
æ ¼å¼ï¼š
{{
  "type": "markdown",
  "title": "...",
  "blocks": [
    {{ "type": "paragraph", "text": "..." }},
    {{ "type": "bullets", "items": ["...", "..."] }},
    {{ "type": "steps", "items": ["...", "..."] }}
  ]
}}

ã€å£è¿°å†…å®¹ã€‘
{text}
"""
    if mode == "latex":
        return f"""
ä½ æ˜¯ä¸€ä¸ªå…¬å¼è½¬å†™å™¨ã€‚

è¯·å°†ä¸‹é¢çš„å£è¿°æ•°å­¦è¡¨è¾¾è½¬å†™ä¸º LaTeX å…¬å¼ã€‚

ã€è¦æ±‚ã€‘
- ä¸åšæ•°å­¦æ¨å¯¼
- åªåšè¡¨è¾¾æ˜ å°„
- åªè¾“å‡º JSON

æ ¼å¼ï¼š
{{
  "type": "latex",
  "latex": "..."
}}

ã€å£è¿°å†…å®¹ã€‘
{text}
"""
    if mode == "mermaid":
        return f"""
ä½ æ˜¯ä¸€ä¸ªæµç¨‹å›¾ç”Ÿæˆå™¨ã€‚

è¯·æ ¹æ®ä¸‹é¢çš„å£è¿°å†…å®¹ç”Ÿæˆ Mermaid flowchart TDã€‚

ã€è¦æ±‚ã€‘
- åªè¾“å‡º JSON
- diagram ä¸­å¿…é¡»æ˜¯åˆæ³• Mermaid

æ ¼å¼ï¼š
{{
  "type": "mermaid",
  "diagram": "flowchart TD\\nA[å¼€å§‹] --> B[å¤„ç†]"
}}

ã€å£è¿°å†…å®¹ã€‘
{text}
"""
    return f"""
è¯·å°†ä¸‹é¢å£è¿°å†…å®¹æ•´ç†æˆç®€æ´ã€é€šé¡ºçš„ä¹¦é¢è¯­ã€‚

ã€åªè¾“å‡º JSONã€‘
æ ¼å¼ï¼š
{{
  "type": "plain",
  "text": "..."
}}

ã€å£è¿°å†…å®¹ã€‘
{text}
"""

# =========================
# æ¸²æŸ“å™¨
# =========================
def render(result: dict) -> str:
    t = result.get("type")
    if t == "plain":
        return result["text"]

    if t == "markdown":
        lines = []
        if result.get("title"):
            lines.append(f"## {result['title']}\n")
        for b in result["blocks"]:
            if b["type"] == "paragraph":
                lines.append(b["text"] + "\n")
            elif b["type"] == "bullets":
                for i in b["items"]:
                    lines.append(f"- {i}")
                lines.append("")
            elif b["type"] == "steps":
                for idx, i in enumerate(b["items"], 1):
                    lines.append(f"{idx}. {i}")
                lines.append("")
        return "\n".join(lines)

    if t == "latex":
        return f"```latex\n{result['latex']}\n```"

    if t == "mermaid":
        return f"```mermaid\n{result['diagram']}\n```"

    return str(result)

# =========================
# å¥å­ç»“æŸ â†’ LLM å¤„ç†
# =========================
def process_final_sentence(text: str):
    mode = route(text)
    print(f"\n\nğŸ§  Router â†’ {mode}")

    prompt = build_prompt(text, mode)
    response = call_ollama(prompt)

    try:
        data = eval(response)  # Demo é˜¶æ®µå¯æ¥å—ï¼Œåç»­æ¢ json.loads
        output = render(data)
        print("\nğŸ“„ ç»“æ„åŒ–è¾“å‡ºï¼š\n")
        print(output)
        print("\n" + "=" * 50)
    except Exception as e:
        print("âš ï¸ è§£æå¤±è´¥ï¼ŒåŸå§‹è¾“å‡ºï¼š")
        print(response)

# =========================
# éŸ³é¢‘å›è°ƒ
# =========================
def record_callback(indata, frames, time_info, status):
    global audio_buffer, last_partial_text, last_text_change_time

    audio = indata[:, 0].astype(np.float32)
    audio_buffer = np.concatenate([audio_buffer, audio])

    while len(audio_buffer) >= CHUNK_STRIDE:
        chunk = audio_buffer[:CHUNK_STRIDE]
        audio_buffer = audio_buffer[CHUNK_STRIDE:]

        res = model.generate(
            input=chunk,
            cache=cache,
            is_final=False,
            chunk_size=CHUNK_SIZE,
            encoder_chunk_look_back=ENCODER_LOOK_BACK,
            decoder_chunk_look_back=DECODER_LOOK_BACK,
        )

        if res and res[0].get("text"):
            text = res[0]["text"]
            if text != last_partial_text:
                print(text, end="", flush=True)
                last_partial_text = text
                last_text_change_time = time.time()

    # åˆ¤æ–­ä¸€å¥è¯ç»“æŸ
    if last_partial_text and (time.time() - last_text_change_time) > SILENCE_TIMEOUT:
        final_text = last_partial_text.strip()
        last_partial_text = ""
        process_final_sentence(final_text)

# =========================
# ä¸»ç¨‹åº
# =========================
print("ğŸ™ Typeless-like æœ¬åœ°è¯­éŸ³è¾“å…¥ Demo")
print("ğŸ‘‰ å¼€å§‹è¯´è¯ï¼Œåœé¡¿ 0.5s è‡ªåŠ¨ç»“æ„åŒ–")
print("ğŸ‘‰ Ctrl+C é€€å‡º\n")

with sd.InputStream(
    samplerate=SAMPLE_RATE,
    channels=1,
    dtype="float32",
    callback=record_callback,
):
    try:
        while True:
            sd.sleep(1000)
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç»“æŸ")